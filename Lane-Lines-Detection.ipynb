{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(images, cols=2, rows=5, cmap=None):\n",
    "    \"\"\"\n",
    "    Display a list of images in a single figure with matplotlib.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 11))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        cmap = 'gray' if len(image.shape) == 2 else cmap\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('test_images'):\n",
    "    test_images = [plt.imread(img) for img in glob.glob('test_images/*.jpg')]\n",
    "    list_images(test_images)\n",
    "else:\n",
    "    print(\"Error: 'test_images' folder not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_color_selection(image):\n",
    "    \"\"\"\n",
    "    Apply color selection to RGB images to blackout everything except for white and yellow lane lines.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    #White color mask\n",
    "    lower_threshold = np.uint8([200, 200, 200])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Yellow color mask\n",
    "    lower_threshold = np.uint8([175, 175,   0])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    yellow_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying color selection to `test_images` in the RGB color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images(list(map(RGB_color_selection, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hsv(image):\n",
    "    \"\"\"\n",
    "    Convert RGB images to HSV.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "list_images(list(map(convert_hsv, test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSV_color_selection(image):\n",
    "    \"\"\"\n",
    "    Apply color selection to the HSV images to blackout everything except for white and yellow lane lines.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    #Convert the input image to HSV\n",
    "    converted_image = convert_hsv(image)\n",
    "    \n",
    "    #White color mask\n",
    "    lower_threshold = np.uint8([0, 0, 210])\n",
    "    upper_threshold = np.uint8([255, 30, 255])\n",
    "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Yellow color mask\n",
    "    lower_threshold = np.uint8([18, 80, 80])\n",
    "    upper_threshold = np.uint8([30, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images(list(map(HSV_color_selection, test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) HSL color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hsl(image):\n",
    "    \"\"\"\n",
    "    Convert RGB images to HSL.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "list_images(list(map(convert_hsl, test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSL_color_selection(image):\n",
    "    \"\"\"\n",
    "    Apply color selection to the HSL images to blackout everything except for white and yellow lane lines.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    #Convert the input image to HSL\n",
    "    converted_image = convert_hsl(image)\n",
    "    \n",
    "    #White color mask\n",
    "    lower_threshold = np.uint8([0, 200, 0])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Yellow color mask\n",
    "    lower_threshold = np.uint8([10, 0, 100])\n",
    "    upper_threshold = np.uint8([40, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    #Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying color selection to `test_images` in the HSL color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_images(list(map(HSL_color_selection, test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_selected_images = list(map(HSL_color_selection, test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gray scaling the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    \"\"\"\n",
    "    Convert images to gray scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image=(list(map(gray_scale, color_selected_images)))\n",
    "list_images = (gray_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Applying Gaussian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(image, kernel_size = 13):\n",
    "    \"\"\"\n",
    "    Apply Gaussian filter to the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            kernel_size (Default = 13): The size of the Gaussian kernel will affect the performance of the detector.\n",
    "            It must be an odd number (3, 5, 7, ...).\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_images = list(map(gaussian_smoothing, gray_images))\n",
    "list_images(blur_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Applying Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
    "    \"\"\"\n",
    "    Apply Canny Edge Detection algorithm to the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            low_threshold (Default = 50).\n",
    "            high_threshold (Default = 150).\n",
    "    \"\"\"\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detected_images = list(map(canny_detector, blur_images))\n",
    "list_images(edge_detected_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_selection(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image)   \n",
    "    #Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #We could have used fixed numbers as the vertices of the polygon,\n",
    "    #but they will not be applicable to images with different dimesnions.\n",
    "    rows, cols = image.shape[:2]\n",
    "    bottom_left  = [cols * 0.1, rows * 0.95]\n",
    "    top_left     = [cols * 0.4, rows * 0.6]\n",
    "    bottom_right = [cols * 0.9, rows * 0.95]\n",
    "    top_right    = [cols * 0.6, rows * 0.6]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = list(map(region_selection, edge_detected_images))\n",
    "list_images(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "        Parameters:\n",
    "            image: The output of a Canny transform.\n",
    "    \"\"\"\n",
    "    rho = 1              #Distance resolution of the accumulator in pixels.\n",
    "    theta = np.pi/180    #Angle resolution of the accumulator in radians.\n",
    "    threshold = 20       #Only lines that are greater than threshold will be returned.\n",
    "    minLineLength = 20   #Line segments shorter than that are rejected.\n",
    "    maxLineGap = 300     #Maximum allowed gap between points on the same line to link them\n",
    "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
    "                           minLineLength = minLineLength, maxLineGap = maxLineGap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_lines = list(map(hough_transform, masked_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(image, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    Draw lines onto the input image.\n",
    "        Parameters:\n",
    "            image: Input image (NumPy array).\n",
    "            lines: List of lines (output of Hough transform).\n",
    "            color (Default = [255, 0, 0]): Line color (BGR format).\n",
    "            thickness (Default = 2): Line thickness.\n",
    "    \"\"\"\n",
    "    image = np.copy(image)\n",
    "    if lines is not None:  # Check if lines is None\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_images = []\n",
    "for image, lines in zip(test_images, hough_lines):\n",
    "    if lines is not None: # check if lines is none before drawing.\n",
    "        line_images.append(draw_lines(image, lines))\n",
    "    else:\n",
    "        line_images.append(image) #Or handle the none case in a different way.\n",
    "list_images(line_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Averaging and extrapolating the lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(lines):\n",
    "    \"\"\"\n",
    "    Calculates the average slope and intercept for left and right lane lines.\n",
    "    \"\"\"\n",
    "    left_lines    = [] #(slope, intercept)\n",
    "    left_weights  = [] #(length,)\n",
    "    right_lines   = [] #(slope, intercept)\n",
    "    right_weights = [] #(length,)\n",
    "\n",
    "    if lines is not None: #add this check.\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if x1 == x2:\n",
    "                    continue # ignore a vertical line\n",
    "                slope = (y2 - y1) / (x2 - x1)\n",
    "                intercept = y1 - slope * x1\n",
    "                length = np.sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
    "                if slope < 0: # left lane\n",
    "                    left_lines.append((slope, intercept))\n",
    "                    left_weights.append((length))\n",
    "                else: # right lane\n",
    "                    right_lines.append((slope, intercept))\n",
    "                    right_weights.append((length))\n",
    "\n",
    "        # ... (rest of your averaging logic) ...\n",
    "        # ... (return left_lane and right_lane) ...\n",
    "        left_lane  = None\n",
    "        right_lane = None\n",
    "        if len(left_weights) > 0:\n",
    "            left_lane = np.average(left_lines, axis=0, weights=left_weights)\n",
    "        if len(right_weights) > 0:\n",
    "            right_lane = np.average(right_lines, axis=0, weights=right_weights)\n",
    "\n",
    "        return left_lane, right_lane\n",
    "    else:\n",
    "        return None, None #Return None, None if lines is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_points(y1, y2, line):\n",
    "    \"\"\"\n",
    "    Converts the slope and intercept of each line into pixel points.\n",
    "        Parameters:\n",
    "            y1: y-value of the line's starting point.\n",
    "            y2: y-value of the line's end point.\n",
    "            line: The slope and intercept of the line.\n",
    "    \"\"\"\n",
    "    if line is None:\n",
    "        return None\n",
    "    slope, intercept = line\n",
    "    x1 = int((y1 - intercept)/slope)\n",
    "    x2 = int((y2 - intercept)/slope)\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    return ((x1, y1), (x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_lines(image, lines):\n",
    "    \"\"\"\n",
    "    Create full length lines from pixel points.\n",
    "        Parameters:\n",
    "            image: The input test image.\n",
    "            lines: The output lines from Hough Transform.\n",
    "    \"\"\"\n",
    "    if lines is not None:\n",
    "        left_lane, right_lane = average_slope_intercept(lines)\n",
    "        if left_lane is not None and right_lane is not None:\n",
    "            y1 = image.shape[0]\n",
    "            y2 = int(y1 * 0.6)  # Convert to integer\n",
    "            left_slope, left_intercept = left_lane\n",
    "            right_slope, right_intercept = right_lane\n",
    "\n",
    "            # Calculate x values for left lane\n",
    "            left_x1 = int((y1 - left_intercept) / left_slope)\n",
    "            left_x2 = int((y2 - left_intercept) / left_slope)\n",
    "\n",
    "            # Calculate x values for right lane\n",
    "            right_x1 = int((y1 - right_intercept) / right_slope)\n",
    "            right_x2 = int((y2 - right_intercept) / right_slope)\n",
    "\n",
    "            # Return lines in the format expected by draw_lines\n",
    "            return [[[left_x1, y1, left_x2, y2]], [[right_x1, y1, right_x2, y2]]]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_images = []\n",
    "for image, lines in zip(test_images, hough_lines):\n",
    "    lane_result = draw_lines(image, lane_lines(image, lines))\n",
    "    if lane_result is not None:\n",
    "        lane_images.append(lane_result)\n",
    "    else:\n",
    "        lane_images.append(image) #or handle it differently.\n",
    "list_images(lane_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply on video streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything needed to edit/save/watch video clips\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import numpy as np #Example of frame processor import.\n",
    "import cv2 #Example of frame processor import.\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(image):\n",
    "    \"\"\"\n",
    "    Process a single frame of the video. (Replace with your actual lane detection logic)\n",
    "    \"\"\"\n",
    "\n",
    "    # Example: Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Example: Apply Gaussian blur\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Example: Canny edge detection\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    # Example: Hough transform (replace with your lane detection)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'test_images\\image.jpg'\n",
    "if os.path.exists(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        processed_image = process_frame(image)\n",
    "        plt.imshow(processed_image)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Error: Could not load image from {image_path}\")\n",
    "else:\n",
    "    print(f\"Error: File not found at {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Process the video and save the output.\n",
    "    \"\"\"\n",
    "    input_clip = VideoFileClip(input_video_path)\n",
    "    output_clip = input_clip.fl(process_frame)\n",
    "    output_clip.write_videofile(output_video_path, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_processor(image):\n",
    "    \"\"\"\n",
    "    Process the input frame to detect lane lines.\n",
    "        Parameters:\n",
    "            image: Single video frame.\n",
    "    \"\"\"\n",
    "    # Access image attributes\n",
    "    height, width, channels = image.shape\n",
    "    data_type = image.dtype\n",
    "    total_pixels = image.size\n",
    "\n",
    "    # Example: Print the attributes\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    print(f\"Image data type: {image.dtype}\")\n",
    "    print(f\"Total pixels: {image.size}\")\n",
    "\n",
    "    color_select = HSL_color_selection(image)\n",
    "    gray         = gray_scale(color_select)\n",
    "    smooth       = gaussian_smoothing(gray)\n",
    "    edges        = canny_detector(smooth)\n",
    "    region       = region_selection(edges)\n",
    "    hough        = hough_transform(region)\n",
    "    result       = draw_lines(image, lane_lines(image, hough))\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB)) #Convert to RGB\n",
    "    plt.show()\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_images\\image.jpg')  # Replace with your image path\n",
    "processed_image = frame_processor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video_path, output_video_path):\n",
    "    \"\"\"\n",
    "    Process the video stream and save the output.\n",
    "    \"\"\"\n",
    "    input_clip = VideoFileClip(input_video_path)\n",
    "    output_clip = input_clip.fl(frame_processor)\n",
    "    output_clip.write_videofile(output_video_path, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_live_video(output_video_path=\"output_videos\\challenge_output.mp4\"):\n",
    "    \"\"\"\n",
    "    Process a live video stream from the webcam.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)  # 0 represents the default camera\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # or 'XVID'\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0 #Get fps, or default to 30.0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video stream\")\n",
    "            break\n",
    "\n",
    "        processed_frame = frame_processor(frame)\n",
    "        out.write(processed_frame)\n",
    "\n",
    "        cv2.imshow('Live Lane Detection', processed_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(test_video, output_video, frame_processor):\n",
    "    \"\"\"\n",
    "    Read input video stream and produce a video file with detected lane lines.\n",
    "        Parameters:\n",
    "            test_video: Input video.\n",
    "            output_video: A video file with detected lane lines.\n",
    "    \"\"\"\n",
    "    input_video = VideoFileClip(os.path.join('test_videos', test_video), audio=False)\n",
    "    processed = input_video.fl(frame_processor)  # Replace fl_image with fl\n",
    "    processed.write_videofile(os.path.join('output_videos', output_video), audio=False)\n",
    "\n",
    "# Example Usage (assuming frame_processor is defined elsewhere)\n",
    "# process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4', frame_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\solidWhiteRight_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('solidYellowLeft.mp4', 'solidYellowLeft_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\solidYellowLeft_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('challenge.mp4', 'challenge_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\challenge_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
